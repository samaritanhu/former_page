<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Xinyi&#39;s gadget">
<meta property="og:url" content="http://nobugs.dev/page/2/index.html">
<meta property="og:site_name" content="Xinyi&#39;s gadget">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Xinyi Hu">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://nobugs.dev/page/2/"/>





  <title>Xinyi's gadget</title>
  








<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

<!-- ҳ����С���� -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>


    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Xinyi's gadget</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-knowme">
          <a href="/KnowMe" rel="section">
            
            KnowMe
          </a>
        </li>
      
        
        <li class="menu-item menu-item-blogs">
          <a href="/archives" rel="section">
            
            Blogs
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-friends">
          <a href="/group" rel="section">
            
            Friends
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/07/19/Computation%20Theory1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/07/19/Computation%20Theory1/" itemprop="url">Elements of the Theory of Computation - Chapter 1 Sets, Relations, and Languages</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-19T14:44:23-07:00">
                2020-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ComputationTheory/" itemprop="url" rel="index">
                    <span itemprop="name">ComputationTheory</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/07/19/Computation%20Theory1/" class="leancloud_visitors" data-flag-title="Elements of the Theory of Computation - Chapter 1 Sets, Relations, and Languages">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  480
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><ul>
<li>an unordered collection of elements</li>
</ul>
<h2 id="subsets-and-proper-subsets"><a href="#subsets-and-proper-subsets" class="headerlink" title="subsets and proper subsets"></a>subsets and proper subsets</h2><ul>
<li><p>Subset notation: $\subseteq$ </p>
<script type="math/tex; mode=display">
S \subseteq T \Leftrightarrow (\forall x \in S \Rightarrow x\in T)</script></li>
<li><p>Proper subset $\subset $ </p>
</li>
</ul>
<h2 id="Set-Operations-and-Its-Identities"><a href="#Set-Operations-and-Its-Identities" class="headerlink" title="Set Operations and Its Identities"></a>Set Operations and Its Identities</h2><ul>
<li>Union, Intersection, Difference, Symmetric difference, complement</li>
<li>Commutative Law, Associative Law, Distributive law, Absorption, DeMorgan’s Law, Idempotent law</li>
</ul>
<h2 id="Power-Set"><a href="#Power-Set" class="headerlink" title="Power Set"></a>Power Set</h2><ul>
<li>$2^S$ = set of all subset of $S$<script type="math/tex; mode=display">
2^S = \{T|T\subseteq S\}</script></li>
</ul>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>A <strong>partition</strong> of nonempty set $A$ is a subset $\sqcap$ of $2^A$ such that</p>
<ol>
<li>$\phi\notin \sqcap $</li>
<li>$\forall S,T \in \sqcap.$ and $S\neq T, S \cap T = \phi$</li>
<li>$\cup \sqcap = A$</li>
</ol>
<h1 id="Relations-and-Functions"><a href="#Relations-and-Functions" class="headerlink" title="Relations and Functions"></a>Relations and Functions</h1><h2 id="Ordered-Pair-and-Binary-Relation"><a href="#Ordered-Pair-and-Binary-Relation" class="headerlink" title="Ordered Pair and Binary Relation"></a>Ordered Pair and Binary Relation</h2><ul>
<li><p>Ordered Pair: $(a,b)$</p>
<script type="math/tex; mode=display">
(a,b)=(c,d) \Leftrightarrow (a=c) \land (b=d)</script></li>
<li><p>Cartesian Product: $A \times B$</p>
<script type="math/tex; mode=display">
A \times B = \{ (a,b)|a\in A \land b\in B\}</script></li>
<li><p>Binary Relation $A$ and $B$</p>
<script type="math/tex; mode=display">
R \subseteq A\times B</script></li>
</ul>
<h2 id="Ordered-Tuple-and-n-ary-Relation"><a href="#Ordered-Tuple-and-n-ary-Relation" class="headerlink" title="Ordered Tuple and n-ary Relation"></a>Ordered Tuple and n-ary Relation</h2><h2 id="Operations-of-Relations"><a href="#Operations-of-Relations" class="headerlink" title="Operations of Relations"></a>Operations of Relations</h2><ul>
<li><p>Inverse</p>
<script type="math/tex; mode=display">
R \subseteq A\times B \Rightarrow R^{-1}\subseteq B\times A</script></li>
<li><p>Composition</p>
</li>
</ul>
<h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><p>Definition: A function $f: A\rightarrow B$ must satisfy:</p>
<ul>
<li>$f \subseteq A \times B$</li>
<li>$\forall a \in A, \exists$ exactly one $b \in B$ with $(a,b) \in f$</li>
</ul>
<p>Note: We write $(a,b)\in f$ as $f(a) = b$</p>
<ul>
<li>one-to-one function: $\forall a,b \in A \land a \neq b \Rightarrow f(a) \neq f(b)$</li>
<li>onto function: $\forall b \in B, \exists a\in A$ such that $f(a)=b$</li>
<li>bijection function: one-to-one + onto </li>
</ul>
<h1 id="Special-Types-of-Binary-Relations"><a href="#Special-Types-of-Binary-Relations" class="headerlink" title="Special Types of Binary Relations"></a>Special Types of Binary Relations</h1><h2 id="Representation-of-Relations"><a href="#Representation-of-Relations" class="headerlink" title="Representation of Relations"></a>Representation of Relations</h2><ul>
<li>Directed graph: node, edge, path</li>
<li>Matrix: Adjacency matrix</li>
</ul>
<h2 id="Properties-of-Relations-R-subseteq-A-times-A"><a href="#Properties-of-Relations-R-subseteq-A-times-A" class="headerlink" title="Properties of Relations ($R \subseteq A\times A$)"></a>Properties of Relations ($R \subseteq A\times A$)</h2><ul>
<li>reflexive: $\forall a\in A \Rightarrow (a,a) \in R$</li>
<li>symmetric: $(a,b) \in R \land a \neq b \Rightarrow (b,a)\in R$, antisymmetric: $(a,b) \in R \Rightarrow (b,a) \notin R$</li>
<li>transitive: $(a.b)\in R, (b,c)\in R \Rightarrow (a,c)\in R$</li>
</ul>
<h2 id="Equivalence-Relation"><a href="#Equivalence-Relation" class="headerlink" title="Equivalence Relation"></a>Equivalence Relation</h2><ul>
<li><p>reflexive, symmetric, transitive</p>
</li>
<li><p>equivalence classes</p>
<script type="math/tex; mode=display">
[a]=\{ b|(a,b)\in R\}</script></li>
</ul>
<p><strong>Theorem</strong> Let $R$ be an equivalence relation on a nonempty set $A$. Then the equivalence classes of $R$ constitute a partition of $A$.</p>
<h2 id="Partial-Order"><a href="#Partial-Order" class="headerlink" title="Partial Order"></a>Partial Order</h2><ul>
<li>reflexive, symmetric, transitive</li>
<li>total order</li>
<li>minimal element and maximal element</li>
</ul>
<h1 id="Finite-and-Infinite-sets"><a href="#Finite-and-Infinite-sets" class="headerlink" title="Finite and Infinite sets"></a>Finite and Infinite sets</h1><h2 id="Equinumerous"><a href="#Equinumerous" class="headerlink" title="Equinumerous"></a>Equinumerous</h2><ul>
<li>Sets $A$ and $B$ equinumerous $\Leftrightarrow \exists$ bijection $f:A\rightarrow B$ </li>
<li>Cardinality and generalized Cardinality</li>
<li>Finite and Infinite sets</li>
</ul>
<h2 id="Countable-and-Uncountable-Infinite"><a href="#Countable-and-Uncountable-Infinite" class="headerlink" title="Countable and Uncountable Infinite"></a>Countable and Uncountable Infinite</h2><ul>
<li>A set is said to be <strong>countably infinite</strong> $\Leftrightarrow$ it is equinumerous with $\mathbb{N}$</li>
<li>S is an uncountable set $\Leftrightarrow |S|&gt;|\mathbb{N}|$</li>
<li>The union of a countably infinite collection of countably infinite sets is countably infinite. </li>
</ul>
<p>Example: Show that $\mathbb{N} \times \mathbb{N}$ is countably infinite.</p>
<p>Theorem: $|\mathbb{R}|&gt;|\mathbb{N}|$ (diagonalization)</p>
<p>Question: Is $|\mathbb{R}| &gt; |(0,1)|$? </p>
<script type="math/tex; mode=display">
f(x)=\frac{1}{\pi}\arctan (x) + \frac12</script><h2 id="Continuum-Hypothesis"><a href="#Continuum-Hypothesis" class="headerlink" title="Continuum Hypothesis"></a>Continuum Hypothesis</h2><p>$|\mathbb{N}|=\aleph_0, |\mathbb{R}|=\aleph_1$</p>
<p>$\aleph_0&lt;\aleph_1$</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/07/19/Hulu%20AI%20class/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/07/19/Hulu%20AI%20class/" itemprop="url">Hulu AI Class - Recommender Systems 1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-19T12:56:21-07:00">
                2020-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/RecommenderSystems/" itemprop="url" rel="index">
                    <span itemprop="name">RecommenderSystems</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/07/19/Hulu%20AI%20class/" class="leancloud_visitors" data-flag-title="Hulu AI Class - Recommender Systems 1">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  881
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="The-aim-of-this-class"><a href="#The-aim-of-this-class" class="headerlink" title="The aim of this class"></a>The aim of this class</h1><ul>
<li>Basic concept of recommender systems</li>
<li>Simple formula and theory</li>
<li>Underlying intuition of each recommendation model</li>
<li>Pros and cons</li>
</ul>
<h1 id="What-is-recommender-system"><a href="#What-is-recommender-system" class="headerlink" title="What is recommender system?"></a>What is recommender system?</h1><p>Basic assumption of recommender systems</p>
<ul>
<li>Information overload</li>
<li>Users are unsure about what they are looking for(different from information retrieval)</li>
</ul>
<p>Target of (traditional) recommender systems</p>
<ul>
<li>Develop a <strong>mathematical model</strong> of an <strong>objective function</strong>($\mathcal{F}$) to predict how much a <strong>user</strong> will like an <strong>item</strong> in a given <strong>context</strong>.</li>
</ul>
<script type="math/tex; mode=display">
R=\mathcal{F}(u, i ; c)</script><p><img src="https://i.loli.net/2020/07/19/cRID18HTiMgsLCn.png" alt="rs1.png"></p>
<h1 id="Basic-Concept"><a href="#Basic-Concept" class="headerlink" title="Basic Concept"></a>Basic Concept</h1><ul>
<li><p>Ratings</p>
</li>
<li><ul>
<li>Explicit ratings: 5 star, like/dislike<em>(additional effort from users)</em></li>
<li>Implicit ratings: page views, click, effective playback, purchase records, whether or not listen to a music track<em>(easier to collect, less precise)</em></li>
</ul>
</li>
<li><p>Interaction matrix</p>
</li>
<li><ul>
<li>Matrix modelling user’s rating on item</li>
<li>User $u$’s rating towards item $i$ as $r_{u,i}$</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2020/07/19/zPJmU6hX3jLNYBK.png" alt="rs1.2.png"></p>
<h1 id="Collaborative-Filtering-“物以类聚，人以群分”"><a href="#Collaborative-Filtering-“物以类聚，人以群分”" class="headerlink" title="Collaborative Filtering “物以类聚，人以群分”"></a>Collaborative Filtering “物以类聚，人以群分”</h1><ul>
<li><p><strong>Context-free</strong> recommender system</p>
</li>
<li><p>Intuition: <strong>the users who have agreed in the past tend to also agree in the future</strong></p>
</li>
<li><p>F: aggregate from nearest neighbor</p>
<script type="math/tex; mode=display">
r_{u, i}=\frac{\sum_{v} w_{u v} \cdot r_{v, i}}{\# \text { of neighbors }}</script></li>
<li><p>User-based CF: user neighbors (green block)</p>
</li>
<li><p>Item-based CF: item neighbors (blue block)</p>
</li>
<li><p>Hybrid: use both</p>
</li>
</ul>
<p><img src="https://i.loli.net/2020/07/19/i4CtNJbxlD39rLM.png" alt="image-20200719113651705.png"></p>
<p><img src="https://i.loli.net/2020/07/19/o7qUYWhifSOZcXy.png" alt="image-20200719113855912.png"></p>
<h2 id="Similarity-Calculation"><a href="#Similarity-Calculation" class="headerlink" title="Similarity Calculation"></a>Similarity Calculation</h2><ul>
<li>Cosine similarity</li>
<li>Pearson correlation</li>
<li>SimRank</li>
</ul>
<h2 id="Improvement-of-Similarity-Calculation"><a href="#Improvement-of-Similarity-Calculation" class="headerlink" title="Improvement of Similarity Calculation"></a>Improvement of Similarity Calculation</h2><ul>
<li>Not all neighbors are equally “valuable” i.e. agreement on commonly liked items not so informative as agreement on controversial items<ul>
<li>Give more weight to items that have a higher variance</li>
</ul>
</li>
<li>Low number of co-rated items may introduce bias<ul>
<li>Reduce “confidence” when the number of co-rated items is low</li>
</ul>
</li>
<li>All neighbors are not very “similar”<ul>
<li>Set similarity threshold</li>
<li>Set maximum number of neighbors</li>
</ul>
</li>
</ul>
<h2 id="Pros-and-Cons"><a href="#Pros-and-Cons" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h2><ul>
<li><p>Pros </p>
<ul>
<li>Easy to implement </li>
<li>Good explanation </li>
</ul>
</li>
<li><p>Cons</p>
<ul>
<li>Large Memory needed </li>
<li>Sparsity issue</li>
</ul>
</li>
</ul>
<h1 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h1><ul>
<li><strong>Context-free</strong> recommender system</li>
<li>Intuition: express <strong>higher-level attributes</strong></li>
<li><p>Generate user and item <strong>embeddings</strong> </p>
<ul>
<li>Latent vectors</li>
<li><p>(A group of) similar users/items have similar embeddings</p>
<p>$\mathcal{F}$  : dot product of embeddings $r_{u,i}=p_u^T q_i$</p>
<script type="math/tex; mode=display">
\min_{p,q} \sum_{(u,i)\in K} (r_{u,i}-p_u^T q_i)^2~+\lambda(||p||+||q||)^2</script></li>
</ul>
</li>
</ul>
<h2 id="Improvement-of-Matrix-Factorization"><a href="#Improvement-of-Matrix-Factorization" class="headerlink" title="Improvement of Matrix Factorization"></a>Improvement of Matrix Factorization</h2><ul>
<li><p>$\mathcal{F}$  could be more complicated</p>
<script type="math/tex; mode=display">
r_{u, i}={\mu}+b_{i}+{b_{u}}+p_{u}^{T} q_{i}</script></li>
<li><p>Global bias </p>
<ul>
<li>Average ratings in the whole catalog </li>
</ul>
</li>
<li><p>Item bias </p>
<ul>
<li>Users rate diﬀerent categories in diﬀerent ways </li>
</ul>
</li>
<li><p>User bias</p>
<ul>
<li>Some users tend to give high ratings while others are not</li>
</ul>
</li>
</ul>
<h2 id="Pros-and-Cons-1"><a href="#Pros-and-Cons-1" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h2><ul>
<li>Pros: <ul>
<li>Better generalization capability: even though two users haven’t rated any same movies, it’s still possible to ﬁnd the similarity between them through embeddings </li>
<li>Low memory: only need to store low-dimensional latent vectors, no need to store large user behaviors </li>
</ul>
</li>
<li>Cons<ul>
<li>Hard to explain </li>
<li>Sparsity</li>
</ul>
</li>
</ul>
<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><ul>
<li><p>Intuition: add <strong>context</strong> information to our model </p>
</li>
<li><p>Recommendation as <strong>classiﬁcation</strong>: </p>
</li>
<li><p>$\mathcal{F}$ </p>
<script type="math/tex; mode=display">
r_{u, i}=\frac{1}{1+e^{-(W x+b)}}</script></li>
<li><p>User, item, context =&gt; <strong>categorical</strong> feature vector</p>
<ul>
<li>Example: gender, time diﬀerence within the day, show genre as feature </li>
<li>$[0, 1, 0, 0, 0, 1, 0]$ =&gt; female, view on morning, target show is <em>Horror Movie</em> </li>
</ul>
</li>
<li><p>Diﬀerent weight of features, <strong>learned by gradient descent</strong> </p>
</li>
<li><p>Sigmoid projection</p>
</li>
</ul>
<h2 id="Logistic-Regression-——-why"><a href="#Logistic-Regression-——-why" class="headerlink" title="Logistic Regression —— why?"></a>Logistic Regression —— why?</h2><ul>
<li><p>Why categorical feature vector? </p>
<ul>
<li>Some non-numerical features, e.g. device: “roku”, “web”, “android”…</li>
<li>Absolute value of feature does not make sense </li>
<li>Feature crossing </li>
<li>Fast computation of sparse vector</li>
</ul>
</li>
<li><p>Why sigmoid projection?</p>
<ul>
<li>Output between 0 and 1 </li>
<li>Good mathematical form </li>
<li>Maximum entropy model</li>
</ul>
</li>
</ul>
<h2 id="Pros-and-Cons-2"><a href="#Pros-and-Cons-2" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h2><ul>
<li>Pros<ul>
<li>Good explanation (feature importance) </li>
<li>Good parallelism, fast model training </li>
<li>Low training cost </li>
<li>Online training </li>
</ul>
</li>
<li>Cons<ul>
<li>Manually craft features</li>
<li>Limited model expressiveness (linear model)</li>
</ul>
</li>
</ul>
<h2 id="Problems-of-Logistic-Regression"><a href="#Problems-of-Logistic-Regression" class="headerlink" title="Problems of Logistic Regression"></a>Problems of Logistic Regression</h2><p>Simpson’s Paradox</p>
<h1 id="Factorization-Machine-FM"><a href="#Factorization-Machine-FM" class="headerlink" title="Factorization Machine (FM)"></a>Factorization Machine (FM)</h1><ul>
<li><p>Intuition: <strong>feature crossing</strong></p>
</li>
<li><p>$\mathcal{F}$</p>
<script type="math/tex; mode=display">
y(x)=\operatorname{sigmoid}\left(w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} w_{i j} x_{i} x_{j}\right)</script></li>
<li><p>Let $w_{ij}=<v_i, v_j="">$ </v_i,></p>
<script type="math/tex; mode=display">
y(x)=sigmoid(w_0 + \sum_{i=1}^n w_ix_i + \sum_{i=1}^{n-1}\sum_{j=i+1}^{n} <v_i,v_j> x_ix_j)</script></li>
<li><p>Deal with parameter explosion ($n^2 \geq nk$)</p>
</li>
<li>Equivalent to low rank parameter matrix factorization $W=VV^T$</li>
</ul>
<h2 id="Pros-and-Cons-3"><a href="#Pros-and-Cons-3" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h2><ul>
<li>Pros<ul>
<li>Good expressiveness </li>
<li>Good generalization </li>
<li>Relatively low training cost</li>
</ul>
</li>
<li>Cons<ul>
<li>Hard to make higher level feature crossing</li>
</ul>
</li>
</ul>
<h1 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting Decision Tree (GBDT)"></a>Gradient Boosting Decision Tree (GBDT)</h1><ul>
<li><p>$\mathcal{F}$</p>
<script type="math/tex; mode=display">
F_m(x)=\sum_{m=1}^M T(x;\theta_m)</script></li>
<li><p>Training samples $(x_1, y_1), (x_2, y_2), … , (x_n,y_n)$</p>
</li>
<li><p>Boosting:</p>
</li>
<li><p>$f$ : Regression tre -&gt; Boosting Regression(Decision) Tree</p>
</li>
<li><p>Loss function -&gt; Gradient Boosting Decision Tree, GBDT</p>
<script type="math/tex; mode=display">
L=\sum_i (f(x_i)-y_i)^2 \\
T(x_i;\theta_m) \approx -[\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}]_{f(x)=F_{m-1}(x)}</script></li>
</ul>
<h2 id="XGBoost-amp-LightGBM"><a href="#XGBoost-amp-LightGBM" class="headerlink" title="XGBoost &amp; LightGBM"></a>XGBoost &amp; LightGBM</h2><ul>
<li><p>$\mathcal{F}$</p>
<script type="math/tex; mode=display">
\hat{y}=\sum_{k=1}^K f_k(x)</script></li>
<li><p>Change optimization goal</p>
<script type="math/tex; mode=display">
O b j^{(t)}=\sum_{i=1}^{m} L\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\sqrt{\gamma T}+\sqrt{\frac{\lambda}{2} \sum_{j=1}^{T} w_{j}^{2}}</script></li>
<li><p>Loss function: Taylor expansion, keep second order terms </p>
</li>
<li>Regularization<ul>
<li>Prevent too complicated trees </li>
<li>Prevent extreme parameters </li>
</ul>
</li>
<li>LightGBM (engineering optimization)</li>
</ul>
<h2 id="Pros-and-Cons-4"><a href="#Pros-and-Cons-4" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h2><ul>
<li>Pros<ul>
<li>Good expressiveness </li>
<li>Low eﬀort of feature engineering </li>
</ul>
</li>
<li>Cons<ul>
<li>Hard parallelism</li>
<li>Unable to do incremental training</li>
</ul>
</li>
</ul>
<h1 id="GBDT-LR"><a href="#GBDT-LR" class="headerlink" title="GBDT + LR"></a>GBDT + LR</h1><ul>
<li>Intuition: <strong>model-based feature engineering</strong></li>
</ul>
<p><img src="https://i.loli.net/2020/07/19/bCaOt84o3Aji2pW.png" alt="image.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/07/18/ESL%20Chapter%2016/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/07/18/ESL%20Chapter%2016/" itemprop="url">The Element of Statistical Learning Chapter 16</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-18T19:37:23-07:00">
                2020-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML-Concepts/" itemprop="url" rel="index">
                    <span itemprop="name">ML Concepts</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/07/18/ESL%20Chapter%2016/" class="leancloud_visitors" data-flag-title="The Element of Statistical Learning Chapter 16">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  474
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Chapter-16-Ensemble-Learning"><a href="#Chapter-16-Ensemble-Learning" class="headerlink" title="Chapter 16. Ensemble Learning"></a>Chapter 16. Ensemble Learning</h1><h2 id="What-is-the-idea-of-Ensemble-Learning"><a href="#What-is-the-idea-of-Ensemble-Learning" class="headerlink" title="What is the idea of Ensemble Learning?"></a>What is the idea of Ensemble Learning?</h2><p>The <strong>idea</strong> of ensemble learning is <strong>to build a prediction model by combining the strengths of a collection of simpler base models</strong>.</p>
<p><a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">Zhou Zhihua</a> Ensemble Learning: <strong>to boost</strong> <strong>weak learner</strong>s which are slightly better than random guess to <strong>strong learners</strong> which can make very accurate predictions.</p>
<p>Ensemble learning can be broken down into <strong>two</strong> tasks:</p>
<p><strong>First</strong>, developing a population of base learners from the training data,</p>
<p><strong>then</strong> combining them to form the composite predictor. </p>
<p>Zhou Zhihua:</p>
<p><strong>First</strong>, a number of base learners are produced, which can be generated in a <em>parallel</em> style or in a <em>sequential</em> style where the generation of a base learner has influence on the generation of subsequent learners. </p>
<p><strong>Then</strong>, the base learners are combined to use, where among the most popular combination schemes are <em>majority votin</em>g for classification and <em>weighted averagin</em>g for regression.</p>
<h2 id="List-some-methods-of-Ensemble-Learning"><a href="#List-some-methods-of-Ensemble-Learning" class="headerlink" title="List some methods of Ensemble Learning."></a>List some <strong>methods</strong> of Ensemble Learning.</h2><ul>
<li><p><strong>Bagging</strong>     </p>
</li>
<li><ul>
<li>trains a number of base learners each from a different <em>bootstrap</em> sample by calling a base      learning algorithm.</li>
<li>After obtaining the base learners, Bagging combines them by majority voting and the most-voted      class is predicted.</li>
<li>Sample: Random Forest</li>
<li>Reduce <strong>variance</strong></li>
</ul>
</li>
<li><p><strong>Boosting</strong>     </p>
</li>
<li><ul>
<li>Is a family of algorithms since there are many variants.</li>
<li>Sample: Adaboost</li>
<li>Reduce <strong>bias</strong></li>
</ul>
</li>
<li><p><strong>Stacking</strong>     </p>
</li>
<li><ul>
<li>A number of first-level individual learners are generated from the training data set      by employing different learning algorithms. </li>
<li>Those individual learners are then combined by a second-level learner which is      called as <em>meta-learner</em>. </li>
</ul>
</li>
</ul>
<blockquote>
<p><em>Bayesian methods for nonparametric regression can also be viewed as ensemble methods</em> </p>
</blockquote>
<p>Generally speaking, there is no ensemble method which outperforms other ensemble methods consistently.</p>
<h2 id="List-some-Penalized-Regression-and-how-they-works"><a href="#List-some-Penalized-Regression-and-how-they-works" class="headerlink" title="List some Penalized  Regression and how they works"></a>List some <strong>Penalized  Regression</strong> and how they works</h2><p><strong>Lasso regression</strong> and <strong>ridge regression</strong>.</p>
<p>Consider the dictionary of all possible J-terminal node regression trees $T=\{T_k\}$ that could be realized on the training data as basis functions in  $R^p$. The linear model is</p>
<script type="math/tex; mode=display">
f(x)=\sum_{k=1}^K \alpha_k T_k(x)</script><p>Suppose the coefficients are to be estimated by <strong>least squares</strong>. Since the number of such trees is likely to be much larger than even the largest training data sets, some form of regularization is required. Let $\hat{\alpha}(\lambda)$ solve</p>
<script type="math/tex; mode=display">
\min_{\alpha}\{\sum_{i=1}^{N}(y_i-\sum_{k=1}^K\alpha_kT_k(x_i))^2+\lambda\cdot J(\alpha)\}</script><p>$J(\alpha)$ is a function of the coefficients that generally penalizes larger values. </p>
<script type="math/tex; mode=display">
J(\alpha)=\sum_{k=1}^K |\alpha_k|^2 - ridge  \\
J(\alpha)=\sum_{k=1}^K |\alpha_k| - lasso</script><h2 id="Why-ensemble-superior-to-Singles-generalization"><a href="#Why-ensemble-superior-to-Singles-generalization" class="headerlink" title="Why ensemble superior to Singles - generalization"></a>Why ensemble superior to Singles - <strong>generalization</strong></h2><ul>
<li>the training data might not provide sufficient information for choosing a single best learner</li>
<li>the search processes of the learning algorithms might be imperfect</li>
<li>the hypothesis space being searched might not contain the true target function, while ensembles can give some good approximation. </li>
</ul>
<p><strong>The bias-variance decomposition</strong> is often used in studying the performance of ensemble methods.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/07/18/ESL%20Chapter%202/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/07/18/ESL%20Chapter%202/" itemprop="url">The Element of Statistical Learning Chapter 2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-18T18:37:23-07:00">
                2020-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML-Concepts/" itemprop="url" rel="index">
                    <span itemprop="name">ML Concepts</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/07/18/ESL%20Chapter%202/" class="leancloud_visitors" data-flag-title="The Element of Statistical Learning Chapter 2">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  182
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Chapter-2-Overview-of-Supervised-Learning"><a href="#Chapter-2-Overview-of-Supervised-Learning" class="headerlink" title="Chapter 2. Overview of Supervised Learning"></a>Chapter 2. Overview of Supervised Learning</h1><p>In stats, <strong>predictors/independent variables</strong> = <strong>input</strong>, <strong>responses/dependent variables</strong> = <strong>output</strong>.</p>
<h2 id="Difference-between-regression-and-classification"><a href="#Difference-between-regression-and-classification" class="headerlink" title="Difference between regression and classification"></a>Difference between <strong>regression</strong> and <strong>classification</strong></h2><p>Regression when we predict quantitative outputs, and classification when we predict qualitative outputs. </p>
<h2 id="Some-notations-on-dataset"><a href="#Some-notations-on-dataset" class="headerlink" title="Some notations on dataset"></a>Some <strong>notations</strong> on dataset</h2><p>We will typically denote an <strong>input</strong> variable by the symbol <strong>X</strong>. <strong>Quantitative outputs</strong> will be denoted by <strong>Y</strong> , and <strong>qualitative outputs</strong> by <strong>G</strong> (for group). </p>
<p><strong>Observed values</strong> are written in lowercase; hence the i-th observed value of <strong>X</strong> is written as .</p>
<p><strong>Matrices</strong> are represented by bold uppercase letters; for example, a set of N input p-vectors , i = 1,…,N would be represented by the N×p matrix <strong>X</strong>. </p>
<p>In general, vectors will not be bold, except when they have N components.</p>
<h2 id="What-is-Nearest-Neighbors"><a href="#What-is-Nearest-Neighbors" class="headerlink" title="What is Nearest Neighbors?"></a>What is <strong>Nearest Neighbors</strong>?</h2><p>Nearest-neighbor methods use those observations in the training set  closest in input space to  to form  . Specifically, the k-nearest neighbor fit for  is defined as follows:</p>
<script type="math/tex; mode=display">
\hat{Y}(x)=\frac{1}{k}\sum_{x_i\in N_k(x)}y_i</script><p>where  is the neighborhood of  defined by the  closest points  in the training sample. </p>
<p>It has <strong>high variance and low bias</strong>.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/06/16/Intermediate%20R/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/06/16/Intermediate%20R/" itemprop="url">Intermediate R</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-06-16T21:39:02-07:00">
                2020-06-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/R/" itemprop="url" rel="index">
                    <span itemprop="name">R</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/06/16/Intermediate%20R/" class="leancloud_visitors" data-flag-title="Intermediate R">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  885
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Equality"><a href="#Equality" class="headerlink" title="Equality"></a>Equality</h1><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">== / identical()</span><br><span class="line">!=</span><br><span class="line">&lt; and &gt; <span class="comment"># greater and less than</span></span><br><span class="line">&amp; <span class="comment"># and</span></span><br><span class="line">| <span class="comment"># or</span></span><br><span class="line">! <span class="comment"># reverse the result</span></span><br></pre></td></tr></table></figure>
<h1 id="Compare"><a href="#Compare" class="headerlink" title="Compare"></a>Compare</h1><h2 id="Compare-vectors"><a href="#Compare-vectors" class="headerlink" title="Compare vectors"></a>Compare vectors</h2><p>linkedin &gt; facebook</p>
<h2 id="Compare-matrices"><a href="#Compare-matrices" class="headerlink" title="Compare matrices"></a>Compare matrices</h2><p>views &lt;= 14</p>
<h1 id="The-if-statement"><a href="#The-if-statement" class="headerlink" title="The if statement"></a>The if statement</h1><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (condition) &#123;</span><br><span class="line">  expr</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (condition2) &#123;</span><br><span class="line">  expr2</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (condition3) &#123;</span><br><span class="line">  expr3</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  expr4</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Write-a-while-loop"><a href="#Write-a-while-loop" class="headerlink" title="Write a while loop"></a>Write a while loop</h1><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (condition) &#123;</span><br><span class="line">  expr</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Stop-the-while-loop"><a href="#Stop-the-while-loop" class="headerlink" title="Stop the while loop:"></a>Stop the while loop:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">break</span><br></pre></td></tr></table></figure>
<h2 id="Loop-over-a-vector"><a href="#Loop-over-a-vector" class="headerlink" title="Loop over a vector"></a>Loop over a vector</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">primes &lt;- c(<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>)</span><br></pre></td></tr></table></figure>
<h3 id="loop-version-1"><a href="#loop-version-1" class="headerlink" title="loop version 1"></a>loop version 1</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (p <span class="keyword">in</span> primes) &#123;</span><br><span class="line">  print(p)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="loop-version-2"><a href="#loop-version-2" class="headerlink" title="loop version 2"></a>loop version 2</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:length(primes)) &#123;</span><br><span class="line">  print(primes[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Loop-over-a-list"><a href="#Loop-over-a-list" class="headerlink" title="Loop over a list"></a>Loop over a list</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">primes_list &lt;- list(<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>)</span><br></pre></td></tr></table></figure>
<h3 id="loop-version-1-1"><a href="#loop-version-1-1" class="headerlink" title="loop version 1"></a>loop version 1</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (p <span class="keyword">in</span> primes_list) &#123;</span><br><span class="line">  print(p)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="loop-version-2-1"><a href="#loop-version-2-1" class="headerlink" title="loop version 2"></a>loop version 2</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:length(primes_list)) &#123;</span><br><span class="line">  print(primes_list[[i]])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Loop-over-a-matrix"><a href="#Loop-over-a-matrix" class="headerlink" title="Loop over a matrix"></a>Loop over a matrix</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (var1 <span class="keyword">in</span> seq1) &#123;</span><br><span class="line">  <span class="keyword">for</span> (var2 <span class="keyword">in</span> seq2) &#123;</span><br><span class="line">    expr</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strsplit()</span><br></pre></td></tr></table></figure>
<h1 id="Function-documentation"><a href="#Function-documentation" class="headerlink" title="Function documentation"></a>Function documentation</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">help(sample)</span><br><span class="line">?sample</span><br><span class="line">args(sample)</span><br></pre></td></tr></table></figure>
<h2 id="Write-your-own-function"><a href="#Write-your-own-function" class="headerlink" title="Write your own function"></a>Write your own function</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_fun &lt;- function(arg1, arg2&#x3D;TRUE) &#123;</span><br><span class="line">  body</span><br><span class="line">  return(result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Load-an-R-Package"><a href="#Load-an-R-Package" class="headerlink" title="Load an R Package"></a>Load an R Package</h2><p>• install.packages(), which as you can expect, installs a given package.<br>• library() which loads packages, i.e. attaches them to the search list on your R workspace. /  require()<br>• search(), to look at the currently attached packages and<br>• qplot(mtcars$wt, mtcars$hp), to build a plot of two variables of the mtcars data frame.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">library(ggplot2)</span><br></pre></td></tr></table></figure>
<h1 id="a-powerful-package-for-data-visualization"><a href="#a-powerful-package-for-data-visualization" class="headerlink" title="a powerful package for data visualization"></a>a powerful package for data visualization</h1><p>Use lapply with a built-in R function</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lapply(X, FUN, ...)</span><br></pre></td></tr></table></figure>
<p>To put it generally, lapply takes a vector or list X, and applies the function FUN to each of its members. </p>
<p>To put it generally, lapply takes a vector or list X, and applies the function FUN to each of its members. </p>
<p>lapply and anonymous functions</p>
<h1 id="Named-function"><a href="#Named-function" class="headerlink" title="Named function"></a>Named function</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">triple &lt;- function(x) &#123; 3 * x &#125;</span><br></pre></td></tr></table></figure>
<h2 id="Anonymous-function-with-same-implementation"><a href="#Anonymous-function-with-same-implementation" class="headerlink" title="Anonymous function with same implementation"></a>Anonymous function with same implementation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">function(x) &#123; 3 * x &#125;</span><br></pre></td></tr></table></figure>
<h1 id="Use-anonymous-function-inside-lapply"><a href="#Use-anonymous-function-inside-lapply" class="headerlink" title="Use anonymous function inside lapply()"></a>Use anonymous function inside lapply()</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lapply(list(1,2,3), function(x) &#123; 3 * x &#125;)</span><br></pre></td></tr></table></figure>
<h2 id="Use-lapply-with-additional-arguments"><a href="#Use-lapply-with-additional-arguments" class="headerlink" title="Use lapply with additional arguments"></a>Use lapply with additional arguments</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">multiply &lt;- function(x, factor) &#123;</span><br><span class="line">  x * factor</span><br><span class="line">&#125;</span><br><span class="line">lapply(list(1,2,3), multiply, factor &#x3D; 3)</span><br></pre></td></tr></table></figure>
<h2 id="How-to-use-sapply"><a href="#How-to-use-sapply" class="headerlink" title="How to use sapply"></a>How to use sapply</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sapply(X, FUN, ...)</span><br></pre></td></tr></table></figure>
<p>sapply() simplifies the list that lapply() would return by turning it into a vector. </p>
<p>sapply() simplifies the list that lapply() would return by turning it into a vector. </p>
<h2 id="Use-vapply"><a href="#Use-vapply" class="headerlink" title="Use vapply"></a>Use vapply</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vapply(X, FUN, FUN.VALUE, ..., USE.NAMES &#x3D; TRUE)</span><br></pre></td></tr></table></figure>
<p>Over the elements inside X, the function FUN is applied. The FUN.VALUE argument expects a template for the return argument of this function FUN. USE.NAMES is TRUE by default; in this case vapply() tries to generate a named array, if possible.</p>
<h1 id="Data-Utilities"><a href="#Data-Utilities" class="headerlink" title="Data Utilities"></a>Data Utilities</h1><p>R features a bunch of functions to juggle around with data structures::<br>    • seq(): Generate sequences, by specifying the from, to, and by arguments.<br>    • rep(): Replicate elements of vectors and lists.<br>    • sort(): Sort a vector in ascending order. Works on numerics, but also on character strings and logicals.<br>    • rev(): Reverse the elements in a data structures for which reversal is defined.<br>    • str(): Display the structure of any R object.<br>    • append(): Merge vectors or lists.<br>    • is.<em>(): Check for the class of an R object.<br>    • as.</em>(): Convert an R object from one class to another.<br>    • unlist(): Flatten (possibly embedded) lists to produce a vector.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grepl &amp; grep</span><br></pre></td></tr></table></figure>
<p>In their most basic form, regular expressions can be used to see whether a pattern exists inside a character string or a vector of character strings. For this purpose, you can use:<br>    • grepl(), which returns TRUE when a pattern is found in the corresponding character string.<br>    • grep(), which returns a vector of indices of the character strings that contains the pattern.</p>
<p>You can use the caret, ^, and the dollar sign, $ to match the content located in the start and end of a string, respectively. This could take us one step closer to a correct pattern for matching only the “.edu” email addresses from our list of emails. But there’s more that can be added to make the pattern more robust:<br>    • @, because a valid email must contain an at-sign.<br>    • .<em>, which matches any character (.) zero or more times (</em>). Both the dot and the asterisk are metacharacters. You can use them to match any character between the at-sign and the “.edu” portion of an email address.<br>    • \.edu​$, to match the “.edu” part of the email at the end of the string. The \\ part escapes the dot: it tells R that you want to use the . as an actual character.</p>
<p>While grep() and grepl() were used to simply check whether a regular expression could be matched with a character vector, sub() and gsub() take it one step further: you can specify a replacement argument. If inside the character vector x, the regular expression pattern is found, the matching element(s) will be replaced with replacement.sub() only replaces the first match, whereas gsub() replaces all matches.</p>
<p>Create and format dates<br>To create a Date object from a simple character string in R, you can use the as.Date() function. The character string has to obey a format that can be defined using a set of symbols (the examples correspond to 13 January, 1982):<br>    • %Y: 4-digit year (1982)<br>    • %y: 2-digit year (82)<br>    • %m: 2-digit month (01)<br>    • %d: 2-digit day of the month (13)<br>    • %A: weekday (Wednesday)<br>    • %a: abbreviated weekday (Wed)<br>    • %B: month (January)<br>    • %b: abbreviated month (Jan)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/06/12/Introduction%20to%20R/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/06/12/Introduction%20to%20R/" itemprop="url">Introduction to R</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-06-12T21:39:02-07:00">
                2020-06-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/R/" itemprop="url" rel="index">
                    <span itemprop="name">R</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/06/12/Introduction%20to%20R/" class="leancloud_visitors" data-flag-title="Introduction to R">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  301
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction-to-R"><a href="#Introduction-to-R" class="headerlink" title="Introduction to R"></a>Introduction to R</h1><p>This guide is a note for datacamp, introduction to R.</p>
<p>I usually use Python, thus in this note, I used Python to contrast R on data collection to data cleaning to data frame…</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>R</th>
<th>Python</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Arithmetic with R </strong> <br>Addition: + <br>Subtraction: - <br>Multiplication: * <br>Division: / <br>Exponentiation: ^ <br>Modulo: %%</td>
<td><br>Addition: + <br>Subtraction: - <br>Multiplication: * <br>Division: / <br>Exponentiation: pow() <br>Modulo: %</td>
</tr>
<tr>
<td><strong>Variable assignment</strong><br>my_var &lt;- 4</td>
<td><strong>Variable assignment</strong><br>my_var = 4</td>
</tr>
<tr>
<td><strong>What’s that data type?</strong><br>class()</td>
<td><strong>Data Type</strong><br>type()</td>
</tr>
<tr>
<td><strong>Create a vector</strong> <br>the combine function c() <br>numeric_vector &lt;- c(1, 2, 3) <br>character_vector &lt;- c(“a”, “b”, “c”)</td>
<td><strong>Create a vector?</strong><br>In python, we have List: []</td>
</tr>
<tr>
<td><strong>Naming a vector</strong> <br>names() <br>some_vector &lt;- c(“John Doe”, “poker player”) <br>names(some_vector) &lt;- c(“Name”, “Profession”)</td>
<td><strong>Naming a vector?</strong><br>I think we normally use another list And we use zip() function to put two lists together. Or we use dict()</td>
</tr>
<tr>
<td>One unique feature: vectors can be added together. If a &lt;- c(1, 2, 3), b &lt;- c(4, 5, 6), then a + b would be c(5, 7, 9)</td>
<td>Lists added together would be like stick together, instead of adding each element one by one. For example, a = [1, 2, 3], b = [4, 5, 6], a + b would be [1, 2, 3, 4, 5, 6]</td>
</tr>
<tr>
<td><strong>Some functions</strong> <br>sum() <br>max() <br>min() <br>mean(na.rm = FALSE) # na.rm: drop NA data <br>abs() <br>round()</td>
<td><strong>Some functions</strong><br>sum() <br>max() <br>min() <br>np.mean()</td>
</tr>
<tr>
<td><strong>Index of vectors</strong> <br>In R, we start from 1.  <br>First element, vector_sample[1]. <br>First to third element, vector_sample[c(1,2,3)] or vector_sample[1:3]</td>
<td><strong>Index of vectors</strong> <br>In python, we start from 0.</td>
</tr>
<tr>
<td><strong>What’s a matrix?</strong> <br>matrix(1:9, byrow = TRUE, nrow = 3) <br>using <code>byrow</code>, we would fill the matrix by rows!</td>
<td>Python doesn’t have this function. We use pandas.DataFrame or numpy to make a matrix, and we can use numpy.reshape.</td>
</tr>
</tbody>
</table>
</div>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/03/30/CS224n%20Classnotes%20Course9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/30/CS224n%20Classnotes%20Course9/" itemprop="url">Stanford CS224n Natural Language Processing Course10</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-30T20:25:23-07:00">
                2020-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/03/30/CS224n%20Classnotes%20Course9/" class="leancloud_visitors" data-flag-title="Stanford CS224n Natural Language Processing Course10">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  215
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Course-10-Question-Answering"><a href="#Course-10-Question-Answering" class="headerlink" title="Course 10 - Question Answering"></a>Course 10 - Question Answering</h1><h2 id="Motivation-History"><a href="#Motivation-History" class="headerlink" title="Motivation/History"></a>Motivation/History</h2><p>With massive collections of full-text documents, return relevant documents.</p>
<p>2 parts</p>
<ol>
<li>find documents that might contain an answer</li>
<li>find an answer in a paragraph or a document</li>
</ol>
<p>MCTest Reading Comprehension: Passage+Question=Answer</p>
<p><img src="https://i.loli.net/2020/04/04/xpvqj1TbEcJkyOL.png" alt="image-20200330135135377.png"></p>
<h2 id="The-SQuAD-dataset"><a href="#The-SQuAD-dataset" class="headerlink" title="The SQuAD dataset"></a>The SQuAD dataset</h2><p>Evalution </p>
<ul>
<li><p>Systems are scored on two metrics</p>
<ul>
<li>exact match</li>
<li>f1:  Precision = tp/(tp+fp), Recall = tp/(tp+tn), F1=2PR/(P+R) - taken as primary</li>
</ul>
<p>Both metrics ignore punctuation and articles (a, an, the only)</p>
</li>
</ul>
<p>Limiations</p>
<ul>
<li>Only span-based answers</li>
<li>Questions were constructed looking at passages</li>
<li>Barely any multi-facts/sentence inference beyonce coreference</li>
</ul>
<p>But still, well-targeted, well-structured, clean dataset</p>
<h2 id="The-Stanford-Attentive-Reader-model"><a href="#The-Stanford-Attentive-Reader-model" class="headerlink" title="The Stanford Attentive Reader model"></a>The Stanford Attentive Reader model</h2><h2 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h2><p><img src="https://i.loli.net/2020/04/04/wpZ5DlvJ7AK4xVY.png" alt="image-20200331105339872.png"></p>
<p>central idea: the Attention Flow layer</p>
<p>Idea: attention should flow both ways - from the context to the question and from the question to the context</p>
<p>Make the similarity matrix:</p>
<script type="math/tex; mode=display">
S_{ij} = w_{sim}^{T}[c_i;q_j;c_i \cdot q_j]</script><p>Context-to-Question attention:</p>
<script type="math/tex; mode=display">
\alpha^{i} = softmax(S_i,:) \in \mathbb{R}^M\\
\alpha_i=\sum_{j=1}^M \alpha_j^i q_j \in \mathbb{R}^{2h}</script><p>Attention Flow Idea: attention should flow both ways</p>
<p>Question-to-Context attention:</p>
<script type="math/tex; mode=display">
m_i=max_j S_{ij} \in \mathbb{R}\\
\beta = softmax(m) \in \mathbb{R}^N\\
c' = \sum_{i=1}^{N} \beta_i c_i \in \mathbb{R}^{2h}</script><h2 id="Recent-more-advanced-architectures"><a href="#Recent-more-advanced-architectures" class="headerlink" title="Recent, more advanced architectures"></a>Recent, more advanced architectures</h2><p>FusionNet</p>
<h2 id="ELMo-and-BERT-preview"><a href="#ELMo-and-BERT-preview" class="headerlink" title="ELMo and BERT preview"></a>ELMo and BERT preview</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/03/16/CS224n%20Classnotes%20Course8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/16/CS224n%20Classnotes%20Course8/" itemprop="url">Stanford CS224n Natural Language Processing Course8</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-16T20:25:23-07:00">
                2020-03-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/03/16/CS224n%20Classnotes%20Course8/" class="leancloud_visitors" data-flag-title="Stanford CS224n Natural Language Processing Course8">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  553
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Course-8-Translation-Seq2Seq-Attention"><a href="#Course-8-Translation-Seq2Seq-Attention" class="headerlink" title="Course 8 - Translation, Seq2Seq, Attention"></a>Course 8 - Translation, Seq2Seq, Attention</h1><h2 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h2><p>from the source language to the target language</p>
<h3 id="Statistical-Machine-Translation"><a href="#Statistical-Machine-Translation" class="headerlink" title="Statistical Machine Translation"></a>Statistical Machine Translation</h3><p>Core idea: learn a probabilistic model from data.</p>
<p>best  English sentence $y$, given French sentence $x$</p>
<script type="math/tex; mode=display">
argmax_y P(y|x)\\
=argmax_y P(x|y) P(y)</script><p>Translation model($P(x|y)$) - Models how words and phrases should be translated. Learnt from <strong>parallel data</strong></p>
<p>note: parallel data - pairs of human-translated french/english sentences.</p>
<p>Language model($P(y)$) - Models how to write good English. Learnt from monolingual data.</p>
<h4 id="Learning-alignment-for-SMT"><a href="#Learning-alignment-for-SMT" class="headerlink" title="Learning alignment for SMT"></a>Learning alignment for SMT</h4><p>alignment is the <em>correspondence between particular words</em> in the translated sentence pair.</p>
<p>Alignment can be <strong>many-to-one</strong> &amp; <strong>one-to-many</strong> &amp; <strong>many-to-many</strong></p>
<p>We learn $P(x, a|y)$ as a combination of many factors.</p>
<h4 id="Decoding-for-SMT"><a href="#Decoding-for-SMT" class="headerlink" title="Decoding for SMT"></a>Decoding for SMT</h4><p>Use a <strong>heuristic search algorithm</strong> to search for the best translation, discarding hypotheses that are too low-probability. This process is called <em>decoding</em></p>
<h3 id="Neural-Machine-Translation"><a href="#Neural-Machine-Translation" class="headerlink" title="Neural Machine Translation"></a>Neural Machine Translation</h3><p><strong>sequence-to-sequence(Seq2seq)</strong> involves 2 RNNs. a <strong>conditional language model</strong></p>
<ul>
<li>conditional - its predictions are conditioned on the source sentence $x$</li>
</ul>
<p><img src="https://i.loli.net/2020/04/04/gixM6LmGa5Ce7Js.png" alt="image-20200328233749255.png"></p>
<p>Other tasks </p>
<ul>
<li>summarization</li>
<li>dialogue</li>
<li>parsing</li>
<li>code generation (natural language -&gt; Python code)</li>
</ul>
<p>NMT directly calculates $P(y|x)$</p>
<script type="math/tex; mode=display">
P(y | x)=P\left(y_{1} | x\right) P\left(y_{2} | y_{1}, x\right) P\left(y_{3} | y_{1}, y_{2}, x\right) \ldots P\left(y_{T} | y_{1}, \ldots, y_{T-1}, x\right)</script><p>Question: How to train?</p>
<p>Answer: Get a big parallel corpus…</p>
<p>Greedy decoding has many problems, it’s an <strong>exhaustive search decoding</strong>, instead we use <strong>beam search decoding</strong></p>
<p>Core idea: On each step of decoder, keep track of the <em>k most probable</em> partial translations (<em>hypotheses</em>)</p>
<ul>
<li><em>k</em> is the <strong>beam size</strong></li>
</ul>
<script type="math/tex; mode=display">
score(y_1,\cdots,y_t)=logP_{LM}(y_1,\cdots,y_t|x)=\sum_{i=1}^t logP_{LM}(y_i|y_1,\cdots,y_{i-1}, x)</script><ul>
<li>Scores are all negative, and higher score is betterr</li>
<li>We search for high-scoring hypotheses, tracking top <em>k</em> on each step</li>
</ul>
<p>Beam search is <em>not guaranteed</em> to find optimal solution, but efficient.</p>
<p>In greedy decoding, usually we decode until the model produces a <END> token. For example, <START> he hit me with a pie <END></END></START></END></p>
<p>Problem：How to select top one with highest score? longer hypotheses have lower scores</p>
<p>Fix: Normalize by length. </p>
<script type="math/tex; mode=display">
\frac{1}{t}\sum_{i=1}^t logP_{LM}(y_i|y_1,\cdots,y_{i-1}, x)</script><h4 id="Advantages-of-NMT"><a href="#Advantages-of-NMT" class="headerlink" title="Advantages of NMT"></a>Advantages of NMT</h4><ul>
<li>better performance.<ul>
<li>more fluent</li>
<li>better use of context</li>
<li>better use of phrase similarities</li>
</ul>
</li>
<li>A single neural network to be optimized end-to-end<ul>
<li>No subcomponents to be individually optimized</li>
</ul>
</li>
<li>Requires much less human engineering effort<ul>
<li>No feature engineering</li>
</ul>
</li>
</ul>
<h4 id="Disadvantages-of-NMT"><a href="#Disadvantages-of-NMT" class="headerlink" title="Disadvantages of NMT"></a>Disadvantages of NMT</h4><p>Compared to SMT:</p>
<ul>
<li>NMT is less interpretable<ul>
<li>Hard to debug</li>
</ul>
</li>
<li>NMT is difficult to control</li>
</ul>
<h4 id="How-to-evaluate"><a href="#How-to-evaluate" class="headerlink" title="How to evaluate?"></a>How to evaluate?</h4><p>BLEU(Bilingual Evaluation Understudy)</p>
<p>BLEU compares the machine-written translation to one or several human-written translations, and computes similarity-score based on:</p>
<ul>
<li>n-gram precision</li>
<li>Plus a penalty for too-short system tranlations</li>
</ul>
<h4 id="Difficulties-remain"><a href="#Difficulties-remain" class="headerlink" title="Difficulties remain"></a>Difficulties remain</h4><p>Out-of-vocabulary words</p>
<p>Domain mismatch between train and test data</p>
<p>Maintaining context over longer text</p>
<p>Low-resource language pairs</p>
<p>NMT picks up <strong>biases</strong> in training data</p>
<p>Uninterpretable system do strange things.</p>
<h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><p>Bottleneck problem.</p>
<p>definition - Given a set of vector <em>values</em>, and a vector <em>query</em>, <strong>attention</strong> is a technique to compute a weighted sum of the values, dependent on the query. </p>
<p>variants</p>
<ul>
<li>Basic dot-product attention</li>
<li>Multiplicative attention</li>
<li>Additive attention</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/03/16/CS224n%20Classnotes%20Course7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/16/CS224n%20Classnotes%20Course7/" itemprop="url">Stanford CS224n Natural Language Processing Course7</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-16T20:25:23-07:00">
                2020-03-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/03/16/CS224n%20Classnotes%20Course7/" class="leancloud_visitors" data-flag-title="Stanford CS224n Natural Language Processing Course7">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  757
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Course-7-Vanishing-Gradients-Fancy-RNN"><a href="#Course-7-Vanishing-Gradients-Fancy-RNN" class="headerlink" title="Course 7 - Vanishing Gradients, Fancy RNN"></a>Course 7 - Vanishing Gradients, Fancy RNN</h1><h2 id="Vanishing-Gradients"><a href="#Vanishing-Gradients" class="headerlink" title="Vanishing Gradients"></a>Vanishing Gradients</h2><p>Gradient can be viewed as a measure of <em>the effect of the past on the future</em></p>
<ul>
<li>There is no dependency between step $t$ and $t+n$ in the data</li>
<li>We have wrong parameters to capture the true dependency between  $t$ and $t+n$ </li>
</ul>
<h2 id="Effect-of-vanishing-gradient-on-RNN-LM"><a href="#Effect-of-vanishing-gradient-on-RNN-LM" class="headerlink" title="Effect of vanishing gradient on RNN-LM"></a>Effect of vanishing gradient on RNN-LM</h2><p>LM task - unable to predict similar long-distance dependencies</p>
<p>Syntactic recency: The <em>writer</em> of the books <strong>is</strong></p>
<p>Sequential recency: The writer of <em>books</em> <strong>are</strong></p>
<p>Due to vanishing gradient, RNN-LMs are better at learning from sequential recency than syntactic </p>
<h2 id="Why-is-exploding-gradient-a-problem"><a href="#Why-is-exploding-gradient-a-problem" class="headerlink" title="Why is exploding gradient a problem?"></a>Why is exploding gradient a problem?</h2><script type="math/tex; mode=display">
\theta^{new} = \theta^{old}-\alpha \nabla_{\theta} J(\theta)</script><h3 id="Solution-gradient-clipping"><a href="#Solution-gradient-clipping" class="headerlink" title="Solution: gradient clipping"></a>Solution: gradient clipping</h3><p>Algorithm 1: Pseudo-code for norm clipping</p>
<p>$\hat{g} \leftarrow \frac{\partial \epsilon}{\partial \theta}$</p>
<p>if $||\hat{g}|| \geq threshold $ then</p>
<p>​    $\hat{g} \leftarrow \frac{threshold}{||\hat{g}||} \hat{g}$</p>
<p>end if </p>
<h2 id="Long-Short-Term-Memory-LSTM"><a href="#Long-Short-Term-Memory-LSTM" class="headerlink" title="Long Short-Term Memory(LSTM)"></a>Long Short-Term Memory(LSTM)</h2><p>On step $t$, there is a hidden state $h^{(t)}$ and a cell state $c^{(t)}$</p>
<ul>
<li>Both are vectors length $n$</li>
<li>The cell stores long-term information</li>
<li>The LSTM can erase, write and read information from the cell</li>
</ul>
<p>The selection is controlled by 3 corresponding <strong>gates</strong></p>
<ul>
<li>vector length $n$</li>
<li>each element of the gates can be open(1), closed(0), or in between</li>
<li>dynamic: their value is computed based on the current context</li>
</ul>
<p>We have a sequence of input $x^{(t)}$, and we will compute a sequence of hidden states $h^{(t)}$ and cell states $c^{(t)}$. On timestep $t$:</p>
<p>Forget gate - controls what is kept vs forgotten, from previous cell state</p>
<script type="math/tex; mode=display">
\boldsymbol{f}^{(t)}={\sigma}\left(\boldsymbol{W}_{f} \boldsymbol{h}^{(t-1)}+\boldsymbol{U}_{f} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{f}\right)</script><p>Input gate - controls what parts of the new cell content are written to cell</p>
<script type="math/tex; mode=display">
\boldsymbol{i}^{(t)}=\sigma\left(\boldsymbol{W}_{i} \boldsymbol{h}^{(t-1)}+\boldsymbol{U}_{i} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{i}\right)</script><p>Output gate - controls what parts of cell are output to hidden state</p>
<script type="math/tex; mode=display">
\boldsymbol{o}^{(t)}={\sigma}\left(\boldsymbol{W}_{o} \boldsymbol{h}^{(t-1)}+\boldsymbol{U}_{o} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{o}\right)</script><p>New cell content - this is the new content to be written to the cell</p>
<script type="math/tex; mode=display">
\tilde{\boldsymbol{c}}^{(t)}=\tanh \left(\boldsymbol{W}_{c} \boldsymbol{h}^{(t-1)}+\boldsymbol{U}_{c} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{c}\right)</script><p>Cell state - erase(“forget”) some content from last cell state, and write(“input”) some new cell content</p>
<script type="math/tex; mode=display">
\boldsymbol{c}^{(t)}=\boldsymbol{f}^{(t)} \circ \boldsymbol{c}^{(t-1)}+\boldsymbol{i}^{(t)} \circ \tilde{\boldsymbol{c}}^{(t)}</script><p>Hidden state: read(“output”) some content from the cell</p>
<script type="math/tex; mode=display">
\boldsymbol{h}^{(t)}=\boldsymbol{o}^{(t)} \circ \tanh \boldsymbol{c}^{(t)}</script><p><img src="https://i.loli.net/2020/04/04/pW7mMj9aDN53h8C.png" alt="image-20200316220913640.png"></p>
<h2 id="Gated-Recurrent-Units-GRU"><a href="#Gated-Recurrent-Units-GRU" class="headerlink" title="Gated Recurrent Units(GRU)"></a>Gated Recurrent Units(GRU)</h2><p>a simpler alternative to the LSTM</p>
<p>On each timestep $t$ we have input $x^{(t)}$ and hidden state $h^{(t)}$ (no cell state)</p>
<p>Update gate - controls what parts of hidden state are updated vs preserved</p>
<script type="math/tex; mode=display">
\boldsymbol{u}^{(t)}=\sigma\left(\boldsymbol{W}_{u} \boldsymbol{h}^{(t-1)}+\boldsymbol{U}_{u} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{u}\right)</script><p>Reset gate - controls what parts of previous hidden state are used to compute new content</p>
<script type="math/tex; mode=display">
\boldsymbol{r}^{(t)}=\sigma\left(\boldsymbol{W}_{r} \boldsymbol{h}^{(t-1)}+\boldsymbol{U}_{r} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{r}\right)</script><p>New hidden state content - reset gate selects useful parts of prev hidden state. Use this and current input to compute new hidden content.</p>
<script type="math/tex; mode=display">
\tilde{\boldsymbol{h}}^{(t)}=\tanh \left(\boldsymbol{W}_{h}\left(\boldsymbol{r}^{(t)} \circ \boldsymbol{h}^{(t-1)}\right)+\boldsymbol{U}_{h} \boldsymbol{x}^{(t)}+\boldsymbol{b}_{h}\right)</script><p>Hidden state - update gate simultaneously controls what is kept from previous hidden state, and what is updated to new hidden state content</p>
<script type="math/tex; mode=display">
\boldsymbol{h}^{(t)}=\left(1-\boldsymbol{u}^{(t)}\right) \circ \boldsymbol{h}^{(t-1)}+\boldsymbol{u}^{(t)} \circ \tilde{\boldsymbol{h}}^{(t)}</script><h2 id="LSTM-vs-GRU"><a href="#LSTM-vs-GRU" class="headerlink" title="LSTM vs GRU"></a>LSTM vs GRU</h2><p>LSTM is a good default choice.</p>
<p>Rule of thumb: start with LSTM, but switch to GRU if you want something more efficient</p>
<h2 id="Vanishing-exploding-gradient"><a href="#Vanishing-exploding-gradient" class="headerlink" title="Vanishing/exploding gradient"></a>Vanishing/exploding gradient</h2><p>add more direct connections.</p>
<p>e.g.: Residual connections, “ResNet”. Skip-connections. The identity connection preserves information by default.</p>
<p>e.g.: Dense connections, “DenseNet”. </p>
<p>e.g.:Highway connections, “HighwayNet”.</p>
<h2 id="Bidirectional-RNNs"><a href="#Bidirectional-RNNs" class="headerlink" title="Bidirectional RNNs"></a>Bidirectional RNNs</h2><p>motivation - task: Sentiment Classification</p>
<p><img src="https://i.loli.net/2020/04/04/on9a2s1Y5jJiADb.png" alt="image-20200317001951410.png"></p>
<p>Note: bidirection RNNs are only applicable if you have access to the entire input sentence. </p>
<p>BERT is built on bidirectionality.</p>
<h2 id="Multi-layer-RNNs-stacked-RNNs"><a href="#Multi-layer-RNNs-stacked-RNNs" class="headerlink" title="Multi-layer RNNs = stacked RNNs"></a>Multi-layer RNNs = stacked RNNs</h2><p>High-performing RNNs are often multi-layer(but aren’t as deep as cn)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://nobugs.dev/2020/03/10/How_powerful_is_gnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xinyi Hu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xinyi's gadget">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/10/How_powerful_is_gnn/" itemprop="url">How powerful is Graph Neural Networks?</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-10T12:56:21-07:00">
                2020-03-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/03/10/How_powerful_is_gnn/" class="leancloud_visitors" data-flag-title="How powerful is Graph Neural Networks?">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="How-powerful-is-Graph-Neural-Networks"><a href="#How-powerful-is-Graph-Neural-Networks" class="headerlink" title="How powerful is Graph Neural Networks?"></a>How powerful is Graph Neural Networks?</h1><p>GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. </p>
<p>There are two tasks of interest: </p>
<p>(1) Node classiﬁcation</p>
<p>(2) Graph classiﬁcation</p>
<p>x Formally, the k-th layer of a GNN is</p>
<script type="math/tex; mode=display">
a_{v}^{(k)}=\operatorname{AGGREGATE}^{(k)}\left(\left\{h_{u}^{(k-1)}: u \in \mathcal{N}(v)\right\}\right), \quad h_{v}^{(k)}=\mathrm{COMBINE}^{(k)}\left(h_{v}^{(k-1)}, a_{v}^{(k)}\right)</script><p> In the pooling variant of GraphSAGE, AGGREGATE has been formulated as </p>
<script type="math/tex; mode=display">
a_{v}^{(k)}=\operatorname{MAX}\left(\left\{\operatorname{ReLU}\left(W \cdot h_{u}^{(k-1)}\right), \forall u \in \mathcal{N}(v)\right\}\right)</script><p>and COMBINE could be concatenation followed by a linear mapping </p>
<script type="math/tex; mode=display">
W \cdot [h_{v}^{(k-1)}, a_{v}^{(k)}]</script><p>Graph Convolutional Networks (GCN) - the element-wise <em>mean</em> pooling is used. AGGREGATE and COMBINE step</p>
<script type="math/tex; mode=display">
h_{v}^{(k)}=\operatorname{ReLU}\left(W \cdot \operatorname{MEAN}\left\{h_{u}^{(k-1)}, \forall u \in \mathcal{N}(v) \cup\{v\}\right\}\right)</script><p>the READOUT function aggregates node features from the ﬁnal iteration to obtain the entire graph’s representation $h_G$</p>
<script type="math/tex; mode=display">
h_{G}=\operatorname{READOUT}\left(\left\{h_{v}^{(K)} | v \in G\right\}\right)</script><p><strong>Deﬁnition1 (Multiset).</strong> A multiset is a generalized concept of a set that allows multiple instances for its elements. More formally, a multiset is a 2-tuple $X = (S,m)$ where $S$ is the underlying set of $X$ that is formed from its distinct elements, and $m : S \rightarrow \mathbb{N}_{\geq 1}$ gives the multiplicity of the elements. </p>
<p><strong>Lemma2</strong>. Let $G_1$ and $G_2$ be any two non-isomorphic graphs. If a graph neural network $A : G→\mathbb{R}^d $ maps $G_1$ and $G_2$ to different embeddings, the Weisfeiler-Lehman graph isomorphism test also decides $G_1$ and $G_2$ are not isomorphic. </p>
<p><strong>Theorem 3</strong>. Let $A : G → \mathbb{R}^d$ be a GNN. With a sufﬁcient number of GNN layers, A maps any graphs $G_1$ and $G_2$ that the Weisfeiler-Lehman test of isomorphism decides as non-isomorphic, to different embeddings if the following conditions hold: </p>
<p>a) $A$ aggregates and updates node features iteratively with </p>
<script type="math/tex; mode=display">
h_{v}^{(k)}=\phi\left(h_{v}^{(k-1)}, f\left(\left\{h_{u}^{(k-1)}: u \in \mathcal{N}(v)\right\}\right)\right)</script><p>where the functions $f$, which operates on multisets, and $φ$ are injective. </p>
<p>b) $A$’s graph-level readout, which operates on the multiset of node features ${h_{v}^{(k)}}$, is injective. </p>
<p><strong>Lemma4</strong>. Assume the input feature space $\mathcal{X}$ is <em>countable</em>. Let $g^{(k)}$ be the function parameterized by a GNN’s k-th layer for $k = 1,…,L$, where $g^{(1)}$ is deﬁned on multisets $X \subset \mathcal{X}$ of bounded size. The range of $g^{(k)}$, i.e., the space of node hidden features ${h_{v}^{(k)}}$, is also countable for all  $k = 1,…,L$.</p>
<p><em>countable</em>: If a set A has the same cardinality as $\mathbb{N}$, then we say that A is <em>countable</em>.</p>
<p><strong>Lemma5</strong>. Assume $\mathcal{X}$ is countable. There exists a function $f : \mathcal{X} →\mathbb{R}^n$ so that  $h(X) =\sum _{x\in X} f(x)$ is unique for each multiset  $X \subset \mathcal{X}$  of bounded size. Moreover, any multiset function $g$ can be decomposed as $g (X) = \varphi(\sum _{x\in X} f(x))$ for some function $\varphi$.</p>
<p><strong>Corollary 6</strong>. Assume $\mathcal{X}$ is countable. There exists a function $f : \mathcal{X} →\mathbb{R}^n$ so that for inﬁnitely many choices of $\epsilon$, including all irrational numbers, $h(c,X) = (1 + \epsilon) · f(c) + \sum_{x \in X} f(x)$ is unique for each pair $(c,X)$, where $c \in \mathcal{X}$ and $X \subset \mathcal{X}$ is a multiset of bounded size. Moreover, any function $g$ over such pairs can be decomposed as $g (c,X) = \varphi((1 + \epsilon)·f(c) + \sum_{x\in X} f(x))$ for some function $\varphi$. </p>
<h2 id="GIN-GRAPH-ISOMORPHISM-NETWORK"><a href="#GIN-GRAPH-ISOMORPHISM-NETWORK" class="headerlink" title="GIN - GRAPH ISOMORPHISM NETWORK"></a>GIN - GRAPH ISOMORPHISM NETWORK</h2><p>To update node representation - </p>
<script type="math/tex; mode=display">
h_{v}^{(k)}=\operatorname{MLP}^{(k)}\left(\left(1+\epsilon^{(k)}\right) \cdot h_{v}^{(k-1)}+\sum_{u \in \mathcal{N}(v)} h_{u}^{(k-1)}\right)</script><p>node learnt can be directly used for tasks like <strong>node classification and link prediction</strong>.</p>
<p>Readout function for graph classiﬁcation tasks. Given embeddings of individual nodes, readout function produces the embedding of the entire graph. </p>
<script type="math/tex; mode=display">
h_{G}=\operatorname{CONCAT}\left(\operatorname{READOUT}\left(\left\{h_{v}^{(k)} | v \in G\right\}\right) | k=0,1, \ldots, K\right)</script><h2 id="GNN-GRAPH-NEURAL-NETWORK"><a href="#GNN-GRAPH-NEURAL-NETWORK" class="headerlink" title="GNN - GRAPH NEURAL NETWORK"></a>GNN - GRAPH NEURAL NETWORK</h2><p>GNN do not satisfy the conditions in Theorem 3, and we conduct ablation studies in </p>
<p>*An ablation study typically refers to removing some “feature” of the model or algorithm, and seeing how that affects performance.</p>
<p>(1) 1-layer perceptrons instead of MLPs</p>
<p>We are interested in understanding whether 1-layer perceptrons are enough for graph learning.</p>
<p><strong>Lemma 7.</strong> There exist ﬁnite multisets $X1 \neq X2$ so that for any linear mapping $W$, $\sum_{x\in X_1} ReLU(Wx) =\sum_{x\in X_2} ReLU(Wx). $</p>
<p>(2) mean or max-pooling instead of the sum.</p>
<p>Mean learns distributions, and max-pooling learns sets with distinct elements.</p>
<p>Consider $X_1 = (S,m)$ and $X_2 = (S,k ·m)$, where $X_1$ and $X_2$ have the same set of distinct elements, but $X_2$ contains $k$ copies of each element of $X_1$.</p>
<p><strong>Corollary 8.</strong> Assume $X$ is countable. There exists a function $f : \mathcal{X} → \mathbb{R^n}$ so that for $h(X) = \frac{1}{|X|}\sum{x\in X} f(x), h(X_1) = h(X_2)$ if and only if multisets $X_1$ and $X_2$ have the same distribution. That is, assuming $|X_2|\geq|X_1|$, we have $X_1 = (S,m)$ and $X_2 = (S,k\cdot m)$ for some $k \in \mathbb{N}_{\geq 1}.$</p>
<p><strong>Corollary 9</strong>. Assume $X$  is countable. Then there exists a function $f : X → \mathbb{R}^{\infty}$ so that for $h(X) = max_{x\in X} f(x), h(X_1) = h(X_2)$ if and only if $X_1$ and $X_2$ have the same underlying set. </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
 <nav class="pagination">
   <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="accessibility.prev_page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="accessibility.next_page"></i></a>
 </nav>

          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="Xinyi Hu" />
            
              <p class="site-author-name" itemprop="name">Xinyi Hu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">36</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/samaritanhu" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:samaritanhu@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.linkedin.com/in/cindy-hu-b98b1a163/" target="_blank" title="Linkedin">
                      
                        <i class="fa fa-fw fa-globe"></i>Linkedin</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        ﻿<div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-snowflake-o"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xinyi Hu</span>

  
</div>

<!--

  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>

-->


    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
 
    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
 



<!--

  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>

-->


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("", "");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  


</body>
</html>
